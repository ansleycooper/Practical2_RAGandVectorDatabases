tim binary search tree order inserting values affects shape tree goal binary search trees minimize height ideal binary search tree complete node last level 2 subnodes hard maintain avl tree approximately balanced binary search tree maintains balance factor value node ensure balance node considered imbalanced absolute value difference height left subtree height right subtree greater 1 node imbalanced considered node imbalance represented alpha four potential cases avl tree become unbalanced leftleft imbalance case 1 height alphas left subtree larger height right subtree recently added node left parent leftright imbalance case 2 height alphas left subtree larger height right subtree recently added node right parent rightleft imbalance case 3 height alphas right subtree larger height left subtree recently added node left parent rightright imbalance case 4 height alphas right subtree larger height left subtree recently added node right parent cases 1 4 cases 2 3 mirrors case 1 case 2 call alphas left child node case 3 4 call alphas right child node case 2 call right child node b case 3 call left child node b rebalance case 1 perform single rotation setting right child alpha moving old right subtree left subtree alpha rebalance case 4 perform single rotation setting left child alpha moving old left subtree right subtree alpha rebalance case 2 first perform single rotation nodes b setting alphas new left child node b setting node bs new left child node setting new right child node bs old left subtree perform first rotation case 2 tree becomes case 1 old node b considered node alpha remains alpha tree balanced using rotation needed case 1 rebalance case 3 first perform single rotation nodes b setting alphas new right child node b setting node bs new right child node setting new left child node bs old right subtree perform first rotation case 3 tree becomes case 4 old node b considered node alpha remains alpha tree balanced using rotation needed case 4 insert node avl tree update heights path newly inserted node root node tree checking imbalance go computer memory stored number different locations descending order speed cpu registers l1 cache l2 cache ram sddhdd sddhdd multiple orders magnitude slower ram lots storage persistent goal database systems minimize number sddhdd accesses since worst case binary search search significantly faster single additional access sddhdd data raw binary search trees good given node binary tree probably occupies fraction cache line btrees way get better locality putting multiple elements tree node btrees originally invented storing data structures disk locality even crucial memory accessing disk location takes 5ms 5000000ns therefore storing tree disk want make sure given disk read effective possible btrees high branching factor much larger 2 ensures disk reads needed navigate place data stored btrees may also useful inmemory data structures days main memory almost slow relative processor disk drives main memory btrees first introduced btree order search tree nonleaf node children actual elements collection stored leaves tree nonleaf nodes contain keys leaf stores number elements maximum number may greater typically less
get better locality putting multiple elements tree node btrees originally invented storing data structures disk locality even crucial memory accessing disk location takes 5ms 5000000ns therefore storing tree disk want make sure given disk read effective possible btrees high branching factor much larger 2 ensures disk reads needed navigate place data stored btrees may also useful inmemory data structures days main memory almost slow relative processor disk drives main memory btrees first introduced btree order search tree nonleaf node children actual elements collection stored leaves tree nonleaf nodes contain keys leaf stores number elements maximum number may greater typically less data structure satisfies several requirements first every path root leaf length second node n children contains n1 keys third every node except root least half full fourth elements stored given subtree keys keys parent node either side subtree pointer generalizes bst invariant fifth root least two children leaf height tree uniformly every node least half full guaranteed asymptotic performance olog n n size collection real win constant factors course choose pointers children plus m1 elements fill cache line highest level memory hierarchy expect get cache hits example accessing large disk database cache lines memory blocks size read disk lookup btree straightforward given node start use simple linear binary search find whether desired element node child pointer follow current node insertion deletion btree complicated insertion first find appropriate leaf node inserted element falls assuming already tree already room node new element inserted simply otherwise current leaf already full must split two leaves one acquires new element parent updated contain new key child pointer parent already full process ripples upwards eventually possibly reaching root root split two new root created two children increasing height tree one deletion works opposite way element removed leaf leaf becomes empty key removed parent node node longer least half full keys parent node immediate right left sibling reapportioned among invariant 3 satisfied possible parent node combined sibling removing key another level tree possibly causing ripple way root root two children combined root deleted new combined node becomes root tree reducing height tree one hash tables effectively function like python dictionary hash table 1dimensional array index stores list contains key value pairs individual tuples size hash table refers large array size hash table denoted letter load factor hash table number inserted elements divided size hash table load factor hash table denoted greek letter lambda inserting hash table works passing key keyvalue pair hashing function inner mechanism hash function important typically returns value mod table size output valid index table keyvalue pair appended tuple end list stored index outputted hash function looking key hash table works passing desired key hash function accessing tuples list stored corresponding index hash table performing linear search match searchedfor key key keyvalue pair want maintain low load factor lambda greater 09 lambda becomes larger 09 rehash table means using larger hash table indices updating hash function accordingly passing stored values new hash function restoring accordingly relational data model several benefits first part standard data
passing key keyvalue pair hashing function inner mechanism hash function important typically returns value mod table size output valid index table keyvalue pair appended tuple end list stored index outputted hash function looking key hash table works passing desired key hash function accessing tuples list stored corresponding index hash table performing linear search match searchedfor key key keyvalue pair want maintain low load factor lambda greater 09 lambda becomes larger 09 rehash table means using larger hash table indices updating hash function accordingly passing stored values new hash function restoring accordingly relational data model several benefits first part standard data model query language used industry second model acid compliant meaning adheres principles atomicity consistency isolation durability third relational model works well highly structured data fourth relational model handle large amounts data finally relational model well understood lots tooling lots experience transaction series crud operations performed single unit work crud stands create read update delete refer main operations perform database transaction could simple select statement involved like joint update statements etc entire transaction either succeeds commit fails rollbackabort four acid properties atomicity consistency isolation durability atomicity means every transaction treated one unit unit either executed full parts executed consistency means transaction takes database one consistent state another consistent state data meets integrity conditions isolation means two transactions affect executed time issue isolation could happen one transaction reading data another transaction writing dirty read first transaction able read row written second transaction yet committed nonrepeatable read transaction returns different data existed started executing finally phantom reads occur transaction reads data twice inserts instances instead durability means transaction completed committed changes permanent shrek 5 set hit theaters 12232026 increase capacity system scale either vertically horizontally scaling vertically refers adding compute within one system scaling horizontally means adding systems compute distributed system collection independent computers appear users one computer main characteristics distributed systems operate concurrently fail independently global clock inevitable distributed systems need network partitioning means systems need partition tolerant words something happens one node system whole fine cap theorem three parts consistency availability partition tolerance theorem states always two three never three consistency means always get result system availability means always access system partition tolerance means system continue operate despite network issues examples products include consistency availability partition tolerance relational database models like postgresql mysql examples products include consistency partition tolerance availability mongo redis hbase examples products include availability partition tolerance consistency couchdb cassandra dynamodb nidhi foundations searching searching common operation performed database system sql select statement arguably versatile complex nest statement baseline efficiency linear search start beginning list proceed element element find youre looking get last element found n elements worst case scenario going n values record collection values attributes single entity instance row table collection set records entity type table collections stored sequentially like list search key value attribute entity type could 1 attribute record takes x bytes memory n records need nx bytes memory 2 ways storing nx bytes ram memory contiguously allocated list nx bytes single chunk memory linked
cassandra dynamodb nidhi foundations searching searching common operation performed database system sql select statement arguably versatile complex nest statement baseline efficiency linear search start beginning list proceed element element find youre looking get last element found n elements worst case scenario going n values record collection values attributes single entity instance row table collection set records entity type table collections stored sequentially like list search key value attribute entity type could 1 attribute record takes x bytes memory n records need nx bytes memory 2 ways storing nx bytes ram memory contiguously allocated list nx bytes single chunk memory linked list x 2 memory addresses identify front versus back n linked list record needs x bytes additional space 1 2 memory addresses individual records linked together type chain using memory addresses python technically true equivalent contiguous array arrays fast random access slow random insertions anywhere end linked lists slow random access fast random insertions binary search keeps going middle iterativelyrecursively must sorted array input array values sorted order target value output location index target located value indicating target found maximum number searches log base 2 n binary search really applies contiguously allocated list super inefficient linked lists best case target found middle 1 comparison inside loop worst case target array log2 n comparisons olog2n time complexity linear search best case target found first element 1 comparison worst case target array n comparisons time complexity lets say table two columns id specialval assume data stored disk id columns value searching specific id would fast want search specific specialval option linear scan column store data disk sorted id specialval time data would duplicated space inefficient therefore need external data structure support faster searching specialval linear scan one current options array tuples specialval rownumber sorted specialval could use binary search quickly locate particular specialval find corresponding row table every insert table would like inserting sorted array slow another option linked list tuples specialval rownumber sorted specialval searching specialval would slow since linear scan required inserting table would theoretically quick also add list something fast insert fast search would solve issue binary search tree every node left subtree less parent every node right subtree greater parent extra notes binary search avl trees httpswwwcsrochestereduugildeacsc282slidesc12bstpdf ttpsicsucieduthorntonics46notesavltrees creatinginserting binary search tree conceptually lets say want insert 23 17 20 42 31 50 23 top node root 17 descend left smaller 20 descend right 17 43 descend left 23 31 go left 50 go right 43 level order traversal tree would 23 17 43 20 31 50 tree traversal types preorder post order order level order processing 23 root print 23 temporarily store 17 43 external data structure print 17 remove external data structure temporarily store 20 remove 43 external data print temporarily store 31 50 remove 20 print child prints 31 print 50 temporarily storing data happens queue python special version called deque binary search tree python class binary tree nodeself value left right value integer left binary tree node right binary tree node root binarytreenode23 rootleft
23 31 go left 50 go right 43 level order traversal tree would 23 17 43 20 31 50 tree traversal types preorder post order order level order processing 23 root print 23 temporarily store 17 43 external data structure print 17 remove external data structure temporarily store 20 remove 43 external data print temporarily store 31 50 remove 20 print child prints 31 print 50 temporarily storing data happens queue python special version called deque binary search tree python class binary tree nodeself value left right value integer left binary tree node right binary tree node root binarytreenode23 rootleft binarytreenode17 rootright binarytreenode43 get 20 rootleftright binarytreenode20 order values inserted binary search tree matters changes shape tree example values sorted would unbalanced tree goal minimize height tree minimum height always going complete tree nodes filled except last level avl tree approximately balanced binary search tree self balancing maintains balance factor node node balanced tree node root tree avl tree absolute value height left sub tree minus height right sub tree less equal 1 basically height left sub tree right sub tree differ 1 inserting avl tree balance imbalance tree would change path recently inserted node root tree becomes imbalanced algorithm rebalance tree alpha root imbalanced node gets reorganized inserting cause imbalance 4 ways left left insertion insert left subtree left child node imbalance left right case insert right subtree left child node imbalance right left case insert left subtree right child right right insert right subtree right child rebalancing rebalancing case 1 single rotation also applies case 4 reassign cs left pointer point t2 reassign right pointer point c rebalancing case 2 double rotation also applies case 3 need separate t2 2 children basically single rotation twice reassignment pointers happens case 4 rr aright points left child c cleft points calculating height node maximum 2 heights nodes subtrees add one larger height memory cpu 16 32 registers depending processor registers closest cpu making fast small expensive l1 cache larger registers slower cheaper per byte l2 cache even larger l1 ram primary memory operates nanosecond speed secondary storage ssds hdds much slower measured milliseconds ssds hdds provide lot storage persistent meaning survive power cycles extremely slow improve speed database systems minimize access secondary storage 64bit integer takes 8 bytes memory lets say avl tree node key value left right pointers 64 bit machine would take 4 8 32 bytes assuming integer takes 8 bytes node stored different block node would need 2048 bytes avl tree 144 log base 2 n n number nodes tree worst case lets say sorted array 128 integers worst case binary search 128 integers way faster single additional disk access even faster would 3 children per node shallowerless tall tree would minimize secondary storage disk accesses important thing database systems b tree b tree designed maximize number values stored disk block node maximum possible number keys reduce disk access node n1 keys n children b tree optimized diskbased indexing minimizing disk access mway tree order maximum number
takes 8 bytes node stored different block node would need 2048 bytes avl tree 144 log base 2 n n number nodes tree worst case lets say sorted array 128 integers worst case binary search 128 integers way faster single additional disk access even faster would 3 children per node shallowerless tall tree would minimize secondary storage disk accesses important thing database systems b tree b tree designed maximize number values stored disk block node maximum possible number keys reduce disk access node n1 keys n children b tree optimized diskbased indexing minimizing disk access mway tree order maximum number keys node m1 maximum number children nodes except root must least half full root requirement insertions always happen leaf level leaves stored doubly linked list keys nodes kept sorted b tree shallower wider bst avl tree number nodes two types nodes internal nodes store keys pointers children leaf nodes store keys data unlike btrees used inmemory indexing b trees designed diskbased indexing relational database management system rdbms increases efficiency indexing direct storage control columnoriented roworiented storage columnoriented faster large data processing materialized views query optimization caching prefetching precompiled stored procedures data replication partitioning improve performance data management column vs roworiented storage columnoriented storage roworiented storage different advantages depending use case transactions must fully completed executed following commit rollbackabort process ensures data integrity error recovery concurrency control reliable data storage simplified error handling relational model offers several benefits including mostly standard data model query language acid compliance atomicity consistency isolation durability strong support highly structured data ability handle large amounts data widespread understanding extensive tooling experience acid acid ensures reliable database transactions four key properties atomicity meaning transaction must fully completed executed none consistency transaction always consistent state data meets integrity constraints isolation preventing one transaction negatively affecting another often managed locking avoid issues like dirty reads transaction reads uncommitted changes another nonrepeatable reads repeated queries within transaction return different results due committed changes another transaction phantom reads rows added deleted another transaction first still running durability guaranteeing transaction committed changes permanent even event system failure relational databases downsides schemas changing time apps needing full acid compliance joins expensive lot data semistructured unstructured like json xml horizontal scaling hard apps need something performant like realtime lowlatency systems scaling conventional wisdom scale vertically bigger powerful systems demands highavailability make necessary scale type distributed computing model scaling easier since need really modify architecture practical financial limits however modern systems make horizontal scaling less problematic one solution distributed systems distributed system collection independent computers appear users one computer andrew tennenbaum characteristics distributed systems computers operate concurrently computers fail independently shared global clock distributed storage 2 directions replication sharding replication data multiple places sharding data broken groups data stored 1 node typically replicated block data available n nodes distributed databases relational nonrelational mysql postgresql support replication sharding cockroachdb new player scene many nosql systems support one models network partitioning inevitable network failures system failures overall system needs partition tolerant words system keep running even network
practical financial limits however modern systems make horizontal scaling less problematic one solution distributed systems distributed system collection independent computers appear users one computer andrew tennenbaum characteristics distributed systems computers operate concurrently computers fail independently shared global clock distributed storage 2 directions replication sharding replication data multiple places sharding data broken groups data stored 1 node typically replicated block data available n nodes distributed databases relational nonrelational mysql postgresql support replication sharding cockroachdb new player scene many nosql systems support one models network partitioning inevitable network failures system failures overall system needs partition tolerant words system keep running even network partition cap theorem states impossible distributed data store simultaneously provide two following three guarantees consistency availability partition tolerance consistency means every read receives recent write error thrown availability means every request receives nonerror response guarantee response contains recent write partition tolerance means system continue operate despite arbitrary network issues cap theorem applied database think like 3 way venn diagram consistency means every user db identical view data given instant definition consistency cap different acid availability means event failure database remains operational partition tolerance means database maintain operations event networks failing two segments distributed system consistency availability means system always responds latest data every request gets response may able deal network issues consistency partition tolerance means system responds data distributed store always latest else data request dropped availability partition tolerance means system always sends responds based distributed store may absolute latest data reality cap theorem says limit number faults requests directed server insist serving every request possibly consistent interpreted must always give something consistency availability tolerance failure nosql key value databases acid transactions focus data safety considered pessimistic concurrency model assumes one transaction must protect transactions aka assumes something go wrong conflicts prevented locking resources transaction complete read write locks write lock analogy says like borrowing book library one else optimistic concurrency says transactions obtain locks data read write considered optimistic assumes conflicts unlikely occur even conflict everything still ok add last update timestamp version number columns every table read changing check end transaction see transaction caused modified low conflict systems backups analytical databases etc read heavy systems conflicts arise handled rolling back rerunning transaction notices conflict optimistic concurrency works well allows higher concurrency high conflict systems work rolling back rerunning transactions encounter conflict less efficient locking scheme pessimistic model might preferable nosql nosql first used 1998 carlo strozzi describe relational database system use sql common modern meaning sql sometimes thought nonrelational databases idea originally developed part response processing unstructured webbased data acid alternative distributed systems called base basically available guarantees availability data per cap response failureunreliable data inconsistent changing state system appears work time soft state says state system could change time even without input changes could result eventual consistency data stores dont writeconsistent replicas dont mutually consistent eventual consistency means system eventually become consistent writes eventually stop nodesreplicas updated key value databases key value keyvalue stores designed around simplicity speed scalability simplicity means data model extremely simple comparatively tables
database system use sql common modern meaning sql sometimes thought nonrelational databases idea originally developed part response processing unstructured webbased data acid alternative distributed systems called base basically available guarantees availability data per cap response failureunreliable data inconsistent changing state system appears work time soft state says state system could change time even without input changes could result eventual consistency data stores dont writeconsistent replicas dont mutually consistent eventual consistency means system eventually become consistent writes eventually stop nodesreplicas updated key value databases key value keyvalue stores designed around simplicity speed scalability simplicity means data model extremely simple comparatively tables rdbms complex simplicity lends simple crud ops api creation speed means usually deployed inmemory db retrieving value given key typically o1 op hash tables similar data structs used hood concept complex queries joins slow things scalability means horizontal scaling simple add nodes typically concerned eventual consistency meaning distributed environment guarantee nodes eventually converge value data science use cases include storing intermediate results data preprocessing exploratory data analysis eda experimenttesting ab results without using production database using feature store fast retrieval frequently accessed features model training prediction model monitoring store key performance metrics especially realtime inference software engineering use cases include storing session information session data saved single put post retrieved quickly get user profiles preferences user settings like language time zone ui preferences fetched single get shopping cart data must tied user accessible across browsers machines sessions using caching layer front diskbased database faster access connection pooling bunch stuff basically makes efficient redis redis remote directory server opensource inmemory database supports durability saving snapshots disk intervals using appendonly file track changes recovery failures sometimes called data structure store primarily keyvalue store though also supports models like graph spatial fulltext search vector time series originally developed 2009 c redis extremely fast handling 100000 set operations per second offers rich collection commands however handle complex data lacks secondary indexes supports lookups key redis keys typically strings binary sequence values various data types including strings lists hashes sets sorted sets geospatial data redis provides 16 default databases numbered 0 15 accessed commands setting retrieving keyvalue pairs many language libraries available foundation data type string maps one string another commonly used caching frequently accessed htmlcssjs storing config settings user info token management counting views rate limiting hash type stores keyvalue entries fieldvalue pairs useful representing objects session management userevent tracking active session tracking list type linked list string values commonly used stacks queues queue management logging social media feeds chat message history batch processing linked lists allow efficient o1 insertion front end json type supports full json syntax stored binary treestructure fast access set type unordered collection unique strings useful tracking unique items eg ip addresses primitive relations eg students course access control lists social network connections redispy standard client python maintained redis redis mysqls3 relational database data stored disk faster latency issues much faster select statements redis pipelines help avoid multiple related calls server needs less network overhead document databases mongodb document database
type linked list string values commonly used stacks queues queue management logging social media feeds chat message history batch processing linked lists allow efficient o1 insertion front end json type supports full json syntax stored binary treestructure fast access set type unordered collection unique strings useful tracking unique items eg ip addresses primitive relations eg students course access control lists social network connections redispy standard client python maintained redis redis mysqls3 relational database data stored disk faster latency issues much faster select statements redis pipelines help avoid multiple related calls server needs less network overhead document databases mongodb document database nonrelational database stores data structured documents usually json designed simple flexible scalable json javascript object notation lightweight datainterchange format easy humans read write easy machines parse generate json built two structures collection namevalue pairs various languages operationalized object record struct dictionary hash table keyed list associative array ordered list values languages operationalized array vector list sequence two universal data structures supported virtually modern programming languages makes json great data interchange format bson binary json binaryencoded serialization jsonlike document structure supports extended types part basic json eg date binarydata etc lightweight keeps space overhead minimum traversable means designed easily traversed vitally important document db efficient encoding decoding must efficient also supported many modern programming languages xml extensible markup language precursor json data exchange format xml css used together web pages content formatting xml structurally like html tag set extensible toolstechnologies used xml xpath syntax retrieving specific elements xml doc xquery query language interrogating xml documents sql xml dtd document type definition language describing allowed structure xml document xslt extensible stylesheet language transformation tool transform xml formats including nonxml formats html document databases address impedance mismatch problem object persistence oo systems relational dbs structure data oo programming inheritance composition types save complex object relational database basically deconstruct structure document selfdescribing wellaligned apps use jsonxml transport layer mongodb mongodb started 2007 doubleclick acquired google 3 veterans realized limitations relational databases serving 400000 ads per second mongodb short humongous database mongodb atlas released 2016 provided documentdb service predefined schema documents needed every document collection could different dataschema rich query support provides robust support crud ops indexing supports primary secondary indices document fields replication supports replica sets automatic failover load balancing built mongodb atlas fully managed mongodb service cloud dbaas mongodb enterprise subscriptionbased selfmanaged version mongodb mongodb community sourceavailable freetouse selfmanaged relational database versus mongo database relational database called database mongodb table view relational database called collection mongodb row relational database called document mongodb column relational database called field mongodb index relational database called index mongodb join relational database called embedded document mongodb foreign key relational database called reference mongodb interacting mongodb done using following mongosh mongodb shell cli tool interacting mongodb instance mongodb compass free opensource gui work mongodb database datagrip 3rd party tools also used every major language library interface mongodb pymongo python mongoose javascriptnode pymongo python library interfacing mongodb instances intro graph data model graph database made nodes connected edges directed undirected
database relational database called database mongodb table view relational database called collection mongodb row relational database called document mongodb column relational database called field mongodb index relational database called index mongodb join relational database called embedded document mongodb foreign key relational database called reference mongodb interacting mongodb done using following mongosh mongodb shell cli tool interacting mongodb instance mongodb compass free opensource gui work mongodb database datagrip 3rd party tools also used every major language library interface mongodb pymongo python mongoose javascriptnode pymongo python library interfacing mongodb instances intro graph data model graph database made nodes connected edges directed undirected edge node uniquely identifiable also add extra properties via key value pairs queries based structure database called cipher examples graph data model social networks web pages chemical biological data underlying thing links pages internet big graph called https 404 error message labelled property graph edgesarcsrelationships nodesvertices type properties keys values labels used mark node part group nodes relationships allowed edges connected nodes path getting one node another order repeating nodes edges matter count nodes edges graph algorithm long consistent connected vs disconnected graphs connected means path two nodes graph weighted vs unweighted means edge weight property important algorithms directed vs undirected means relationships edges define start end node directed graphs loop arrows going ways acyclic vs cyclic means graph contains cycles spare vs dense number edges compared number nodes trees cycles pathfinding finding shortest path mean fewest edges lowest weight summed average shortest path used monitor efficiency resiliency network pagerank search engines used use number links website first search result became many pages link pages link page breadth first search visit nearest neighbors first different depth first search walks branch first centrality determining nodes important network compared nodes degree closeness betweenness pagerank community detection evaluating clustering partitioning nodes graph tendency strengthen break apart famous graph algorithms include dijkstras algorithm singlesource shortest path algo positively weighted graphs algorithm similar dijkstras added feature using heuristic guide traversal pagerank measures importance node within graph based number incoming relationships importance nodes incoming relationships neo4j neo4j nosql database supports transactional analytical processing graphbased data relatively new schemaoptional acidcompliant supports various types indexing distributed computing similar databases include microsoft cosmosdb amazon neptune neo4j uses cypher graph query language created 2011 supports plugins like apoc additional functions graph data science plugin running graph algorithms docker compose tool managing multicontainer applications using yaml configuration file allows starting stopping scaling services single command ensuring consistent environments interaction mostly command line env files help manage environment variables across platforms neo4j relationships directed docker compose docker compose supports multicontainer management declarative setup using yaml file dockercomposeyaml define services volumes networks single command start stop scale multiple services ensuring consistent environment interaction mostly command line env files store environment variables keep settings separate across platforms envlocal envdev envprod port numbers maximum port number 65535 range ports system services need root access 01023 http 80 https 443 ssh 22 ftp 21 retrieval augmented generation rag outputs contextual input words pdf class notes contextual
scaling services single command ensuring consistent environments interaction mostly command line env files help manage environment variables across platforms neo4j relationships directed docker compose docker compose supports multicontainer management declarative setup using yaml file dockercomposeyaml define services volumes networks single command start stop scale multiple services ensuring consistent environment interaction mostly command line env files store environment variables keep settings separate across platforms envlocal envdev envprod port numbers maximum port number 65535 range ports system services need root access 01023 http 80 https 443 ssh 22 ftp 21 retrieval augmented generation rag outputs contextual input words pdf class notes contextual elements augmenting already model context ansley searching database systems searching common operation database systems sql select statement one versatile complex operations baseline efficiency linear search linear search starts beginning list proceeds element element 1 target found 2 last element reached without finding target key terms record collection attribute values single entity instance row table collection set records entity type table search key value attribute used search single multiple attributes lists records memory usage record takes x bytes n records total memory required n x bytes contiguously allocated list n x bytes allocated single memory block linked list record takes x bytes plus additional memory one two addresses link records together contiguous vs linked lists contiguous allocated list array memory allocated single block faster random access slower insertions except end linked list records linked memory addresses extra storage needed address faster insertions anywhere list slower random access insertion examples array inserting second record requires moving 5 records make space linked list inserting second record require moving records observations arrays fast random access slow insertions linked lists slow random access fast insertions binary search input sorted array target value output index target indication found def binarysearcharr target left right 0 lenarr 1 left right mid left right 2 arrmid target return mid elif arrmid target left mid 1 else right mid 1 return 1 example sorted array target located adjusting left right based midpoint comparison time complexity linear search best case o1 target found first element worst case target found binary search best case o1 target found midpoint worst case olog2 n target found searching databases storing id fast searching specific id searching special value linear scan required inefficient issue storing data id special value possible store data sorted id special value time due space inefficiency solution external data structures option 1 array tuples specialval rownumber sorted specialval binary search quickly find specialval inserting slow array sorted option 2 linked list tuples specialval rownumber sorted specialval insertion fast searching requires linear scan fast insert search binary search tree bst provide fast insertion searching bst node left subtree less parent node node right subtree greater parent node relational databases distributed systems benefits relational model mostly standard data model query language acid compliance works well highly structured data handle large amounts data well understood extensive tooling expertise relational database performance enhancements indexing direct storage control columnoriented vs roworiented storage query optimization cachingprefetching materialized views
array tuples specialval rownumber sorted specialval binary search quickly find specialval inserting slow array sorted option 2 linked list tuples specialval rownumber sorted specialval insertion fast searching requires linear scan fast insert search binary search tree bst provide fast insertion searching bst node left subtree less parent node node right subtree greater parent node relational databases distributed systems benefits relational model mostly standard data model query language acid compliance works well highly structured data handle large amounts data well understood extensive tooling expertise relational database performance enhancements indexing direct storage control columnoriented vs roworiented storage query optimization cachingprefetching materialized views precompiled stored procedures data replication partitioning transaction processing transaction sequence one crud operations performed single logical unit work either entire sequence succeeds commit entire sequence fails rollback abort benefits data integrity error recovery concurrency control reliable data storage simplified error handling acid properties atomicity transaction treated atomic unit either fully executed parts executed consistency transaction takes database one consistent state another consistent state data meets integrity constraints isolation two transactions t1 t2 execute simultaneously affect t1 t2 reading data problem t1 reads data t2 may writing potential issues include dirty read t1 reads row modified uncommitted t2 nonrepeatable read t1 executes query twice gets different values t2 committed changes phantom reads t1 running t2 addsdeletes rows set t1 using durability transaction completes commits successfully changes permanent changes preserved even system failure example transaction money transfer sqlcopydelimiter create procedure transfer senderid int receiverid int amount decimal102 begin declare rollbackmessage varchar255 default transaction rolled back insufficient funds declare commitmessage varchar255 default transaction committed successfully start transaction start transaction attempt debit money sender update accounts set balance balance amount accountid senderid attempt credit money receiver update accounts set balance balance amount accountid receiverid check sufficient funds sender account select balance accounts accountid senderid 0 roll back transaction insufficient funds rollback signal sqlstate 45000 45000 unhandled userdefined error set messagetext rollbackmessage else log transactions sufficient funds insert transactions accountid amount transactiontype values senderid amount withdrawal insert transactions accountid amount transactiontype values receiverid amount deposit commit transaction commit select commitmessage result end end delimiter limitations relational databases schemas evolve time applications need full acid compliance join operations expensive semistructured unstructured data json xml handled optimally horizontal scaling challenges performance limitations realtime lowlatency systems scalability vertical vs horizontal conventional wisdom scale vertically bigger powerful systems scale horizontally highavailability necessitates distributed computing considerations vertical scaling simpler architecture changes practical financial limits modern systems make horizontal scaling manageable distributed systems distributed system collection independent computers appear users one computer andrew tanenbaum characteristics computers operate concurrently computers fail independently shared global clock distributed storage approaches distributed data stores data stored multiple nodes typically replicated block data available n nodes relational nonrelational mysql postgresql support replication sharding cockroachdb newer distributed sql database many nosql systems support distribution models important consideration network partitioning inevitable network failures system failures occur overall system needs partition tolerant continue running despite network partitions cap theorem cap theorem states distributed data store simultaneously provide two three
changes practical financial limits modern systems make horizontal scaling manageable distributed systems distributed system collection independent computers appear users one computer andrew tanenbaum characteristics computers operate concurrently computers fail independently shared global clock distributed storage approaches distributed data stores data stored multiple nodes typically replicated block data available n nodes relational nonrelational mysql postgresql support replication sharding cockroachdb newer distributed sql database many nosql systems support distribution models important consideration network partitioning inevitable network failures system failures occur overall system needs partition tolerant continue running despite network partitions cap theorem cap theorem states distributed data store simultaneously provide two three guarantees consistency every read receives recent write error availability every request receives nonerror response guaranteed contain recent write partition tolerance system operates despite arbitrary network issues database view cap tradeoffs consistency availability system always responds latest data every request gets response may handle network partitions well consistency partition tolerance system responds data always latest otherwise data request dropped sacrifices availability availability partition tolerance system always responds may provide absolute latest data common choice distributed systems cap reality really means limit fault numbers requests go server insist serving every request consistency impossible common interpretation must always sacrifice one consistency availability partition tolerance nosql keyvalue databases distributed databases concurrency models pessimistic concurrency acid focuses data safety assumes transactions need protection transactions conflicts prevented locking resources transaction completion uses read write locks analogy borrowing library book one else use details databases guarantee isolation optimistic concurrency transactions obtain locks data readingwriting assumes conflicts unlikely occur implementation add timestamp version columns tables read changing data check transaction end another transaction modified works well lowconflict systems backups analytical dbs readheavy systems systems tolerate rollbacks retries less efficient highconflict systems locking may preferable nosql overview term nosql first used 1998 carlo strozzi relational database without sql modern meaning sql sometimes interpreted nonrelational dbs developed partly response processing unstructured webbased data brief history nonrelational databases cap theorem 2 3 following consistency every user identical view data given instant availability database remains operational failures partition tolerance database maintains operations despite network failures system segments note consistency cap differs consistency acid cap tradeoffs consistency availability system always responds latest data may handle network partitions consistency partition tolerance system responds latest data drops request availability partition tolerance system always responds may provide absolute latest data base model acid alternative distributed systems basically available data available might inconsistent changing soft state system state may change without input due eventual consistency data stores dont require writeconsistency replicas dont require mutual consistency eventual consistency system eventually become consistent writes stop keyvalue databases core design principles simplicity extremely simple data model key value supports basic crud operations api creation much simpler relational tables speed typically deployed inmemory databases o1 retrieval operations using hash tables similar structures complex queries joins slow things scalability easy horizontal scaling adding nodes uses eventual consistency distributed environments use cases data science applications edaexperimentation results store intermediate results data preprocessing ab testing results without production db impact feature store lowlatency retrieval
state may change without input due eventual consistency data stores dont require writeconsistency replicas dont require mutual consistency eventual consistency system eventually become consistent writes stop keyvalue databases core design principles simplicity extremely simple data model key value supports basic crud operations api creation much simpler relational tables speed typically deployed inmemory databases o1 retrieval operations using hash tables similar structures complex queries joins slow things scalability easy horizontal scaling adding nodes uses eventual consistency distributed environments use cases data science applications edaexperimentation results store intermediate results data preprocessing ab testing results without production db impact feature store lowlatency retrieval model training prediction model monitoring store realtime performance metrics software engineering applications session information storage fast singleoperation retrieval storage user profiles preferences language timezone ui preferences shopping cart data crossbrowserdevice availability caching layer frontend diskbased databases redis remote directory server overview open source inmemory database sometimes called data structure store primarily kv store supports models graph spatial full text search vector time series topranked keyvalue store according dbenginescom key features inmemory supports data durability disk snapshots intervals appendonly file journal rollforward recovery originally developed 2009 c performance 100000 set operationssecond rich command set limitations complex data secondary indexes lookup key data types keys usually strings binary sequence values strings lists linked lists sets unique unsorted string elements sorted sets hashes string string geospatial data json redis databases 16 databases default numbered 015 naming conventions interaction commands language libraries redis data types commands strings simplest data type maps string string store text serialized objects binary arrays use cases caching htmlcssjs fragments configurationuser settings token management page view counting rate limiting string commands copyset pathtoresource 0 set user1 john doe get pathtoresource exists user1 del user1 keys user select 5 select database 5 incr somevalue increment 1 incrby somevalue 10 increment 10 decr somevalue decrement 1 decrby somevalue 5 decrement 5 setnx key value set key doesnt exist hashes value collection fieldvalue pairs use cases represent basic objectsstructures session information management userevent tracking active session tracking hash commands copyhset bike1 model demios brand ergonom price 1971 hget bike1 model hget bike1 price hgetall bike1 hmget bike1 model price weight hincrby bike1 price 100 lists value linked list string values use cases stacks queues implementation message passing queues logging systems social media streamsfeeds chat application message history batch processing task queues list commands copy queue operations lpush bikesrepairs bike1 lpush bikesrepairs bike2 rpop bikesrepairs stack operations lpush bikesrepairs bike1 lpush bikesrepairs bike2 lpop bikesrepairs operations llen mylist lrange mylist 0 3 elements index 0 3 lrange mylist 0 0 first element lrange mylist 2 1 last two elements sets unordered collection unique strings use cases track unique items ip addresses primitive relations access control lists social network friendsgroup membership supports set operations set commands copysadd ds4300 mark sadd ds4300 sam sadd cs3200 nick sadd cs3200 sam sismember ds4300 mark check membership scard ds4300 count elements sinter ds4300 cs3200 intersection sdiff ds4300 cs3200 difference srem ds4300 mark remove element srandmember ds4300 random member json
bikesrepairs stack operations lpush bikesrepairs bike1 lpush bikesrepairs bike2 lpop bikesrepairs operations llen mylist lrange mylist 0 3 elements index 0 3 lrange mylist 0 0 first element lrange mylist 2 1 last two elements sets unordered collection unique strings use cases track unique items ip addresses primitive relations access control lists social network friendsgroup membership supports set operations set commands copysadd ds4300 mark sadd ds4300 sam sadd cs3200 nick sadd cs3200 sam sismember ds4300 mark check membership scard ds4300 count elements sinter ds4300 cs3200 intersection sdiff ds4300 cs3200 difference srem ds4300 mark remove element srandmember ds4300 random member json type full support json standard uses jsonpath syntax parsingnavigating stored internally binary tree structure fast subelement access redis setup guide prerequisites docker desktop installed jetbrains datagrip installed step 1 find redis image open docker desktop use builtin search find redis image click run step 2 configure run container give new container name enter 6379 host port field standard redis port click run allow docker time download start redis step 3 set data source datagrip start datagrip create new redis data source either clicking icon database explorer selecting new file menu step 4 configure data source give data source name install drivers needed message appear test connection required test connection redis click ok connection test successful notes redis store various data types strings numbers json objects binary objects etc drivers arent already installed datagrip show message test connection button redispy guide overview redispy official python client redis maintained redis inc github redisredispy installation pip install redis storage capability handles strings numbers json objects binary data connection pythoncopyimport redis connect redis server redisclient redisredis hostlocalhost docker localhost 127001 port6379 default redis port db2 database number 015 decoderesponsestrue converts byte responses strings key commands data type string operations pythoncopy basic operations redisclientsetclickcountabc 0 value redisclientgetclickcountabc redisclientincrclickcountabc multiple operations redisclientmsetkey1 val1 key2 val2 key3 val3 values redisclientmgetkey1 key2 key3 returns val1 val2 val3 available string commands write set mset setex msetnx setnx read get mget getex getdel numeric incr decr incrby decrby text strlen append list operations pythoncopy create populate list redisclientrpushnames mark sam nick allnames redisclientlrangenames 0 1 returns mark sam nick available list commands left operations lpush lpop right operations rpush rpop management lset lrem lrange llen lpos hash operations pythoncopy create populate hash redisclienthsetusersession123 mapping first sam last uelle company redis age 30 get hash fields userdata redisclienthgetallusersession123 available hash commands basic hset hget hgetall management hkeys hdel hexists hlen hstrlen pipelines reduce network overhead batching multiple commands pythoncopy create pipeline pipe redisclientpipeline set multiple values one execution range5 pipesetfseati fi results pipeexecute true true true true true chain commands results redisclientpipelinegetseat0getseat3getseat4execute results 0 3 4 redis mldata science redis serves essential component ml architectures feature stores vector databases model serving caching layers realtime processing resources full redis command list redispy documentation document database document database nonrelational database stores data structured documents usually json designed simple flexible scalable json json javascript object notation lightweight datainterchange format easy humans read write easy
basic hset hget hgetall management hkeys hdel hexists hlen hstrlen pipelines reduce network overhead batching multiple commands pythoncopy create pipeline pipe redisclientpipeline set multiple values one execution range5 pipesetfseati fi results pipeexecute true true true true true chain commands results redisclientpipelinegetseat0getseat3getseat4execute results 0 3 4 redis mldata science redis serves essential component ml architectures feature stores vector databases model serving caching layers realtime processing resources full redis command list redispy documentation document database document database nonrelational database stores data structured documents usually json designed simple flexible scalable json json javascript object notation lightweight datainterchange format easy humans read write easy machines parse generate json built two structures 1 collection namevalue pairs eg object record dictionary hash table associative array 2 ordered list values eg array vector list sequence two structures supported almost modern programming languages making json ideal data interchange format json syntax binary json bson bson binary json binaryencoded serialization jsonlike document structure supports extended types like date binarydata lightweight minimize space overhead designed easily traversed important document databases efficient encoding decoding supported many programming languages xml extensible markup language xml precursor json data exchange format xml css used create web pages separate content formatting xml structurally similar html tag set extensible xmlrelated toolstechnologies xpath syntax retrieving specific elements xml document xquery query language xml documents similar sql dtd language define structure xml document xslt tool transform xml formats including html document databases document databases solve impedance mismatch problem objectoriented programming oop relational databases structure data oop inheritance composition types used however saving complex objects relational database requires deconstructing document databases allow structure document selfdescribing making natural fit applications use jsonxml data transport mongodb mongodb started 2007 doubleclick acquired google three veterans realized limitations relational databases serving 400000 ads per second mongodb short humongous database mongodb atlas released 2016 offering document databases service mongodb structure database collection collection b collection c document 1 document 2 document 3 mongodb documents predefined schema documents every document collection different schema relational vs mongodocument db rdbms vs mongodb database database tableview collection row document column field index index join embedded document foreign key reference mongodb features rich query support full support crud operations indexing supports primary secondary indexes document fields replication supports replica sets automatic failover load balancing builtin load balancing mongodb versions mongodb atlas fully managed mongodb service dbaas mongodb enterprise subscriptionbased selfmanaged version mongodb community sourceavailable freetouse selfmanaged version interacting mongodb mongosh mongodb shell cli tool mongodb compass free opensource gui working mongodb datagrip 3rdparty tools libraries interface mongodb various languages eg pymongo python mongoose javascript mongodb community edition docker create container map hostcontainer port 27017 provide initial username password superuser mongodb compass gui tool interacting mongodb download install official website load mflix sample data set 1 create new database called mflix 2 download unzip mflix sample dataset 3 import json files users theaters movies comments new collections mflix database creating database collection use mongosh interact mongodb find queries mongodb similar sql select statements example select users dbusersfind filter users name
mongosh mongodb shell cli tool mongodb compass free opensource gui working mongodb datagrip 3rdparty tools libraries interface mongodb various languages eg pymongo python mongoose javascript mongodb community edition docker create container map hostcontainer port 27017 provide initial username password superuser mongodb compass gui tool interacting mongodb download install official website load mflix sample data set 1 create new database called mflix 2 download unzip mflix sample dataset 3 import json files users theaters movies comments new collections mflix database creating database collection use mongosh interact mongodb find queries mongodb similar sql select statements example select users dbusersfind filter users name dbusersfindname davos seaworth filter movies released 2010 specific rating genre dbmoviesfindyear 2010 awardswins gte 5 genres drama count documents collection count documents use countdocuments method example count movies 2010 least 5 awards drama genre dbmoviescountdocumentsyear 2010 awardswins gte 5 genres drama pymongo pymongo python library interfacing mongodb instances pymongo pymongo python library interfacing mongodb instances getting database collection pymongo import mongoclient client mongoclient mongodbusernamepwlocalhost27017 db clientds4300 clientds4300 collection dbmycollection dbmycollection inserting single document db clientds4300 collection dbmycollection post author mark text mongodb cool tags mongodb python postid collectioninsertonepostinsertedid printpostid find movies 2000 bsonjsonutil import dumps find movies released 2000 movies2000 dbmoviesfindyear 2000 print results printdumpsmovies2000 indent2 jupyter time activate ds4300 conda venv python environment install pymongo pip install pymongo install jupyter lab python environment pip install jupyterlab download unzip zip file contains 2 jupyter notebooks terminal navigate folder unzipped files run jupyter lab graph databases graph theory graph database data model based graph data structure composed nodes vertices edges relationships edges connect nodes element uniquely identified contain properties eg name occupation supports graphoriented operations traversals shortest path algorithms many specialized queries realworld graph applications social networks social media platforms instagram facebook modeling social interactions psychology sociology web large graph pages nodes connected hyperlinks edges chemical biological data systems biology genetics chemical interaction relationships labeled property graph model composed node vertex objects relationship edge objects labels used mark nodes part group properties keyvalue pair attributes exist nodes relationships structure rules nodes relationships permitted edges connected nodes allowed graph example components 2 labels person car 4 relationship types drives owns liveswith marriedto properties attributes attached nodes relationships paths graphs path ordered sequence nodes connected edges nodes edges repeated example valid path 1 2 6 5 invalid path 1 2 6 2 3 node 2 repeats graph types properties connected vs disconnected connected path exists two nodes graph disconnected contains isolated components paths weighted vs unweighted weighted edges weight property important certain algorithms unweighted weights assigned edges directed vs undirected directed relationships edges define specific start end node undirected relationships direction cyclic vs acyclic cyclic graph contains least one cycle acyclic graph contains cycles sparse vs dense sparse relatively edges compared maximum possible dense many edges approaching maximum possible number trees tree special type graph connected acyclic undirected node except root exactly one parent graph algorithms overview pathfinding algorithms definition find shortest path nodes fewest edges lowest weight use case monitor network efficiency
path exists two nodes graph disconnected contains isolated components paths weighted vs unweighted weighted edges weight property important certain algorithms unweighted weights assigned edges directed vs undirected directed relationships edges define specific start end node undirected relationships direction cyclic vs acyclic cyclic graph contains least one cycle acyclic graph contains cycles sparse vs dense sparse relatively edges compared maximum possible dense many edges approaching maximum possible number trees tree special type graph connected acyclic undirected node except root exactly one parent graph algorithms overview pathfinding algorithms definition find shortest path nodes fewest edges lowest weight use case monitor network efficiency resiliency using average shortest path variants minimum spanning tree cycle detection maxmin flow algorithms search approaches bfs breadthfirst search explores neighbors moving deeper dfs depthfirst search explores far possible along branches backtracking centrality community detection centrality identifies important nodes network eg social network influencers community detection evaluates clusteringpartitioning nodes cohesion famous graph algorithms dijkstras algorithm singlesource shortest path positively weighted graphs algorithm enhanced dijkstras uses heuristics guide traversal pagerank measures node importance based incoming relationships sources neo4j type graph database system supporting transactional analytical processing classification nosql database schemaoptional design features various indexing capabilities acid compliance distributed computing support similar systems microsoft cosmos db amazon neptune optimized format eliminates unnecessary numbering 1522 organizes content logical sections uses consistent formatting llms easily process understand cells celltype markdown id 02ead21fdc3b4536aa57f2ead5395348 metadata source mongodb aggregation examples celltype markdown id 66da7d8d4c4f4c608e22d0c023c35a0f metadata source ensure pymongo installed running cells notebook celltype code executioncount null id 5e29baf989a046189f912c8087128b7d metadata outputs source import pymongon bsonjsonutil import dumpsn import pprintn n update uri username password n n uri mongodbmarkabc123localhost27017n client pymongomongoclienturin mflixdb clientmflixn demodb clientdemodb celltype markdown id 1565e7882c724ab6a5b336e05334233b metadata source aggregates pymongon n aggregation uses pipelinesn pipeline sequence stages documents proceedn different stages used matchn projectn sortn limitn unwindn groupn lookup celltype markdown id 921429f53125475eb0afa871b9a0799e metadata source match celltype code executioncount null id 1a9f528f5ffa40fa99b65a3bc36b3e33 metadata scrolled true outputs source c mflixdbmoviesaggregaten match year lte 1920n n n printdumpsc indent4 celltype markdown id e180713d92ec4392ba996c5a96775903 metadata source match project celltype code executioncount null id cc479ecc724149d79cc25a57cd40bb5c metadata scrolled true outputs source c mflixdbmoviesaggregaten match year lte 1920n project id0 title 1 cast 1n n n printdumpsc indent4 celltype markdown id 7f7d7755e9fa4061ac985f31b75201f2 metadata source match project limit sort celltype code executioncount null id d7e42c04668e4dd6abf77a081c126c13 metadata scrolled true outputs source c mflixdbmoviesaggregaten match year lte 1920n sort title 1n limit 5n project id0 title 1 cast 1n n n printdumpsc indent4 celltype markdown id 6e58c4a2ff4248a18493aba643b7592d metadata source unwind celltype code executioncount null id 02ac7ecc69ee45cb83efb271afaccbe1 metadata scrolled true outputs source c mflixdbmoviesaggregaten match year lte 1920n sort imdbrating 1n limit 5n unwind castn project id0 title 1 cast 1 rating imdbratingn n n printdumpsc indent4 celltype markdown id 4a2edddc422e4f678ddb87343c5eb004 metadata source grouping celltype code executioncount null id 4e3b2ef1681c4cf4baba7d1399de1dd1 metadata scrolled true outputs source average imdb rating movies year sort data yearn n c mflixdbmoviesaggregaten group id release year year avg rating avg imdbratingn sort id 1n n n printdumpsc indent 2 celltype code executioncount
title 1 cast 1n n n printdumpsc indent4 celltype markdown id 6e58c4a2ff4248a18493aba643b7592d metadata source unwind celltype code executioncount null id 02ac7ecc69ee45cb83efb271afaccbe1 metadata scrolled true outputs source c mflixdbmoviesaggregaten match year lte 1920n sort imdbrating 1n limit 5n unwind castn project id0 title 1 cast 1 rating imdbratingn n n printdumpsc indent4 celltype markdown id 4a2edddc422e4f678ddb87343c5eb004 metadata source grouping celltype code executioncount null id 4e3b2ef1681c4cf4baba7d1399de1dd1 metadata scrolled true outputs source average imdb rating movies year sort data yearn n c mflixdbmoviesaggregaten group id release year year avg rating avg imdbratingn sort id 1n n n printdumpsc indent 2 celltype code executioncount null id 665047a187cb422f91ae645714020a32 metadata scrolled true outputs source average imdb rating movies year sort data avg rating decreasing ordern n c mflixdbmoviesaggregaten group id release year year avg rating avg imdbratingn sort avg rating 1 id 1n n n printdumpsc indent 2 celltype markdown id f3bb33037cce44f2a9bb7503ee2741e1 metadata source lookup celltype code executioncount null id 6f869bbe701b4fb3980fbe9f1879b1ed metadata scrolled true outputs source data demodbcustomersaggregaten n lookup n ordersn localfield custidn foreignfield custidn ordersn n n project id 0 address 0n n printdumpsdata indent 2 celltype markdown id 7e24db4a38f04464ab8b19d675af29db metadata source reformatting queries celltype code executioncount null id 1d7f801c05e14c05baad673c36302d20 metadata outputs source match match year lte 1920n limit limit 5n project project id0 title 1 cast 1 rating imdbratingn n agg mflixdbmoviesaggregatematch limit projectn printdumpsagg indent2 celltype code executioncount null id 76e9276d938d45e392f4f2daa42ce704 metadata outputs source metadata kernelspec displayname python 3 ipykernel language python name python3 languageinfo codemirrormode name ipython version 3 fileextension py mimetype textxpython name python nbconvertexporter python pygmentslexer ipython3 version 3119 nbformat 4 nbformatminor 5 cells celltype markdown id 02ead21fdc3b4536aa57f2ead5395348 metadata source mongodb pymongo example queries celltype markdown id 66da7d8d4c4f4c608e22d0c023c35a0f metadata source make sure mongodb container runningn make sure pymongo installed running cells notebook use pip install pymongo celltype code executioncount null id 5e29baf989a046189f912c8087128b7d metadata outputs source import pymongon bsonjsonutil import dumpsn n update uri username password n n uri mongodbusernamepasswordlocalhost27017n client pymongomongoclienturin mflixdb clientmflix celltype code executioncount null id e4ec02e07f9240dca6dbc0bd0e2d5b32 metadata outputs source setup demodb 2 collectionsn demodbcustomersdropn demodbordersdropn n customers n custid c13 name cruise address street 201 main st city st louis mo zipcode 63101 rating 750 n custid c25 name streep address street 690 river st city hanover zipcode 02340 rating 690 n custid c31 name b pitt address street 360 mountain ave city st louis mo zipcode 63101 n custid c35 name j roberts address street 420 green st city boston zipcode 02115 rating 565 n custid c37 name hanks address street 120 harbor blvd city boston zipcode 02115 rating 750 n custid c41 name r duvall address street 150 market st city st louis mo zipcode 63101 rating 640 n custid c47 name loren address street via del corso city rome italy rating 625 n n n orders n orderno 1001 custid c41 orderdate 20170429 shipdate 20170503 items itemno 347 qty 5 price 1999 itemno 193 qty 2 price 2889 n orderno 1002 custid c13 orderdate 20170501 shipdate 20170503 items itemno 460 qty 95 price
420 green st city boston zipcode 02115 rating 565 n custid c37 name hanks address street 120 harbor blvd city boston zipcode 02115 rating 750 n custid c41 name r duvall address street 150 market st city st louis mo zipcode 63101 rating 640 n custid c47 name loren address street via del corso city rome italy rating 625 n n n orders n orderno 1001 custid c41 orderdate 20170429 shipdate 20170503 items itemno 347 qty 5 price 1999 itemno 193 qty 2 price 2889 n orderno 1002 custid c13 orderdate 20170501 shipdate 20170503 items itemno 460 qty 95 price 10099 itemno 680 qty 150 price 875 n orderno 1003 custid c31 orderdate 20170615 shipdate 20170616 items itemno 120 qty 2 price 8899 itemno 460 qty 3 price 9999 n orderno 1004 custid c35 orderdate 20170710 shipdate 20170715 items itemno 680 qty 6 price 999 itemno 195 qty 4 price 3500 n orderno 1005 custid c37 orderdate 20170830 items itemno 460 qty 2 price 9998 itemno 347 qty 120 price 2200 itemno 780 qty 1 price 150000 itemno 375 qty 2 price 14998 n orderno 1006 custid c41 orderdate 20170902 shipdate 20170904 items itemno 680 qty 51 price 2598 itemno 120 qty 65 price 8500 itemno 460 qty 120 price 9998 n orderno 1007 custid c13 orderdate 20170913 shipdate 20170920 items itemno 185 qty 5 price 2199 itemno 680 qty 1 price 2050 n orderno 1008 custid c13 orderdate 20171013 items itemno 460 qty 20 price 9999 n n n demodbcustomersinsertmanycustomersn demodbordersinsertmanyordersn n numcustomers demodbcustomerscountdocumentsn numorders demodborderscountdocumentsn n printfthere numcustomers customers numorders orders celltype code executioncount null id 4b977e9f6cc54afb91edfc7eec781c4e metadata scrolled true outputs source key id attribute automatically returned unless explicitly say remove n n select name rating customersn data demodbcustomersfind name1 rating1n printdumpsdata indent2 celltype code executioncount null id 38d4b61959894962b3e6ec1893095d72 metadata scrolled true outputs source without id field n n select name rating customersn data demodbcustomersfind name1 rating1 id0n printdumpsdata indent2 celltype markdown id 1be795017f8b43afa9559e9f95f842f2 metadata source fields except specific ones returned celltype code executioncount null id 48385e0ffe324abd91a0ef8e732046c3 metadata scrolled true outputs source every customer return fields except id addressn n data demodbcustomersfind id 0 address 0n printdumpsdata indent2 celltype markdown id d929a63257de4de580496dada9027e6b metadata source equivalent sql like operator celltype code executioncount null id 84e41240518641f1ba943935e333e255 metadata outputs source select name rating customers name like tn n regular expression explanationn match beginning linen match literal character beginning line casen match single character except newlinen match zero occurrences previous character casen n data demodbcustomersfindname regex id 0 name 1 rating1n printdumpsdata indent2 celltype markdown id 95c0ac04ab9d4a34850a16137cd1fc1d metadata source sorting limiting celltype code executioncount null id e07bf0b910f14fae97f019ff2afda9bf metadata outputs source select name rating customers order rating limit 2n n data demodbcustomersfind id 0 name 1 rating1 sortratinglimit2n printdumpsdata indent2 celltype code executioncount null id 08236f133f9447dabd19f931c59039e4 metadata outputs source sorting desc ordern n select name rating customers order rating desc limit 2n n data demodbcustomersfind id 0 name 1 rating1 sortrating 1limit2n printdumpsdata indent2 celltype code executioncount null id 7ae8e68534d549b3af1e5a0f5ed6186c metadata outputs source
single character except newlinen match zero occurrences previous character casen n data demodbcustomersfindname regex id 0 name 1 rating1n printdumpsdata indent2 celltype markdown id 95c0ac04ab9d4a34850a16137cd1fc1d metadata source sorting limiting celltype code executioncount null id e07bf0b910f14fae97f019ff2afda9bf metadata outputs source select name rating customers order rating limit 2n n data demodbcustomersfind id 0 name 1 rating1 sortratinglimit2n printdumpsdata indent2 celltype code executioncount null id 08236f133f9447dabd19f931c59039e4 metadata outputs source sorting desc ordern n select name rating customers order rating desc limit 2n n data demodbcustomersfind id 0 name 1 rating1 sortrating 1limit2n printdumpsdata indent2 celltype code executioncount null id 7ae8e68534d549b3af1e5a0f5ed6186c metadata outputs source providing 2 sort keys n n data demodbcustomersfind id 0 name 1 rating1 sortrating 1 name 1limit2n printdumpsdata indent2 celltype markdown id 143f4349d0cf4812a27cf627f709d8ae metadata source turn mflix db celltype markdown id 3e6cbf7978134df0838600b4c133ba0a metadata source question 1 celltype code executioncount 16 id ca28ccf2bff143bea1b62c7f735e4c3b metadata outputs source many users mflix database many moviesn celltype markdown id e520f1c3f9bf46688d847ef605c5bd90 metadata source question 2 celltype code executioncount null id 224682d354484fcd83b0b4938b083b24 metadata outputs source movies rating tvg return title yearn n celltype markdown id 2a86daefc330493d92d538517d7c4381 metadata source question 3 celltype code executioncount null id 566f45002eb54190abdfbfb9228d5c3f metadata scrolled true outputs source movies runtime less 20 minutes return title runtime movie n n celltype markdown id 05d0bfebeb464fe0a25754b632f1c34f metadata source question 4 celltype code executioncount null id 86821f3ea95e40fda8bb3afb7078cc6b metadata outputs source many theaters mn man n celltype markdown id d3c90cac74bc4b699a08b8118bf97bfd metadata source question 5 celltype code executioncount null id 03c20e7f2d7247c5b104083cca731cb5 metadata scrolled true outputs source give names movies comments yet make sure names alphabetical order n n celltype markdown id dd98ae0a0d114d33a5a805f6a7da052e metadata source question 6 celltype code executioncount null id 2c5e0923d2ec4e86a85f57c4ef523b6f metadata scrolled true outputs source return list movie titles actors movie title contains word four n sort list title n metadata kernelspec displayname python 3 ipykernel language python name python3 languageinfo codemirrormode name ipython version 3 fileextension py mimetype textxpython name python nbconvertexporter python pygmentslexer ipython3 version 3119 nbformat 4 nbformatminor 5
